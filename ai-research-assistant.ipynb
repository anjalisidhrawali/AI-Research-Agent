{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install -q groq arxiv PyPDF2 termcolor requests tenacity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T05:11:28.990013Z","iopub.execute_input":"2025-08-28T05:11:28.990264Z","iopub.status.idle":"2025-08-28T05:11:37.086189Z","shell.execute_reply.started":"2025-08-28T05:11:28.990236Z","shell.execute_reply":"2025-08-28T05:11:37.085309Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Importing Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport time\nimport json\nimport requests\nfrom dataclasses import dataclass\nfrom typing import List, Tuple, Optional\n\nimport arxiv\nfrom PyPDF2 import PdfReader\nfrom termcolor import colored\nfrom tenacity import retry, wait_exponential_jitter, stop_after_attempt, retry_if_exception_type\nfrom groq import Groq\nfrom groq._exceptions import RateLimitError, APIStatusError\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\ngroq_api_key = user_secrets.get_secret(\"GROQ_API_KEY\")\n\nos.environ[\"GROQ_API_KEY\"] = groq_api_key\n\nGROQ_MODEL = \"llama-3.1-70b-versatile\"\n\n# Pipeline parameters\nMAX_RESULTS = 10\nNUMBER_OF_TURNS = 10\nINITIAL_SEARCH_TERM = \"coding ability of large language models\"\nPAPERS_DIR = \"research_papers\"\n\n# Chunking — character-based\nCHUNK_SIZE = 6000\nCHUNK_OVERLAP = 400       \nMAX_CHUNKS = 30\n\n# Output controls\nMAX_SUMMARY_TOKENS = 512 \nTEMPERATURE = 0.3         \n\n# Basic checks\nif not groq_api_key:\n    print(colored(\"⚠️  Missing GROQ_API_KEY. Set it in your environment or this cell.\", \"yellow\"))\nelse:\n    print(colored(\"✓ GROQ API key detected\", \"green\"))\nprint(colored(f\"Using Groq model: {GROQ_MODEL}\", \"cyan\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T05:11:40.788646Z","iopub.execute_input":"2025-08-28T05:11:40.788939Z","iopub.status.idle":"2025-08-28T05:11:42.155615Z","shell.execute_reply.started":"2025-08-28T05:11:40.788908Z","shell.execute_reply":"2025-08-28T05:11:42.154859Z"}},"outputs":[{"name":"stdout","text":"✓ GROQ API key detected\nUsing Groq model: llama-3.1-70b-versatile\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Helper Function","metadata":{}},{"cell_type":"code","source":"def sanitize_folder_name(name: str, max_length: int = 60) -> str:\n    s = re.sub(r'[\\\\/*?:\"<>|]', \"_\", name).strip()\n    s = re.sub(r\"\\s+\", \"_\", s)\n    if len(s) > max_length:\n        s = s[:max_length].rsplit(\"_\", 1)[0]\n    return s or \"untitled\"\n\ndef ensure_dir(path: str) -> str:\n    os.makedirs(path, exist_ok=True)\n    return path\n\ndef chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP, max_chunks: int = MAX_CHUNKS) -> List[str]:\n    if not text:\n        return []\n    chunks = []\n    i = 0\n    n = len(text)\n    while i < n and len(chunks) < max_chunks:\n        end = min(i + chunk_size, n)\n        chunks.append(text[i:end])\n        if end == n:\n            break\n        i = end - overlap\n        if i < 0: i = 0\n    return chunks\n\ndef save_text(path: str, content: str):\n    ensure_dir(os.path.dirname(path))\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        f.write(content)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T05:11:48.954910Z","iopub.execute_input":"2025-08-28T05:11:48.955457Z","iopub.status.idle":"2025-08-28T05:11:48.963840Z","shell.execute_reply.started":"2025-08-28T05:11:48.955430Z","shell.execute_reply":"2025-08-28T05:11:48.963038Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# ArXiv tools (Client API)","metadata":{}},{"cell_type":"code","source":"def get_arxiv_papers(query: str, max_results: int = 5):\n    try:\n        client = arxiv.Client(page_size=max_results)\n        search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n        return list(client.results(search))\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return []\n\ndef download_pdf(url: str, filename: str, folder: str) -> str:\n    os.makedirs(folder, exist_ok=True)\n    path = os.path.join(folder, filename)\n    r = requests.get(url, timeout=60)\n    r.raise_for_status()\n    with open(path, \"wb\") as f:\n        f.write(r.content)\n    return path\n\ndef extract_text_from_pdf(pdf_path: str) -> str:\n    reader = PdfReader(pdf_path)\n    return \"\\n\".join([page.extract_text() or \"\" for page in reader.pages]).strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T05:11:59.332147Z","iopub.execute_input":"2025-08-28T05:11:59.332877Z","iopub.status.idle":"2025-08-28T05:11:59.339657Z","shell.execute_reply.started":"2025-08-28T05:11:59.332850Z","shell.execute_reply":"2025-08-28T05:11:59.338622Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Groq (LLaMA) Chat Helpers","metadata":{}},{"cell_type":"code","source":"client = None\nif groq_api_key:\n    client = Groq(api_key=groq_api_key)\n\n@retry(\n    wait=wait_exponential_jitter(initial=1, max=20),\n    stop=stop_after_attempt(5),\n    retry=retry_if_exception_type((RateLimitError, APIStatusError, requests.exceptions.RequestException))\n)\ndef llama_chat(messages, model=GROQ_MODEL, temperature=TEMPERATURE, max_tokens=MAX_SUMMARY_TOKENS):\n    if client is None:\n        raise RuntimeError(\"Groq client not initialized (missing key).\")\n    resp = client.chat.completions.create(\n        model=model, messages=messages, temperature=temperature, max_tokens=max_tokens\n    )\n    return resp.choices[0].message.content.strip()\n\ndef choose_paper_with_llama(papers) -> Tuple[Optional[int], str]:\n    listing = [f\"{i}. {p.title.strip()}\\nAbstract: {(p.summary or '').strip()}\" for i, p in enumerate(papers)]\n    prompt = (\n        \"You are a careful academic assistant. From the numbered list of papers, \"\n        \"pick the SINGLE best paper for the search term. \"\n        \"Respond in exactly this JSON format:\\n\"\n        '{ \"choice\": <number>, \"reason\": \"<brief reason without numeric lists>\" }\\n\\n'\n        \"Papers:\\n\" + \"\\n\".join(listing)\n    )\n    messages = [\n        {\"role\": \"system\", \"content\": \"You select the most promising academic paper and explain briefly.\"},\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n    try:\n        out = llama_chat(messages, max_tokens=256)\n        m = re.search(r'\\{.*\\}', out, re.S)\n        if m:\n            j = json.loads(m.group(0))\n            return int(j.get(\"choice\")), j.get(\"reason\", \"\")\n        return (int(re.search(r'(\\d+)', out).group(1)) if re.search(r'(\\d+)', out) else None), out\n    except Exception:\n        return None, \"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T05:12:09.585361Z","iopub.execute_input":"2025-08-28T05:12:09.585985Z","iopub.status.idle":"2025-08-28T05:12:09.946118Z","shell.execute_reply.started":"2025-08-28T05:12:09.585963Z","shell.execute_reply":"2025-08-28T05:12:09.945288Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Summarization Helpers","metadata":{}},{"cell_type":"code","source":"def safe_summarize_text(text: str):\n    chunks = chunk_text(text, CHUNK_SIZE, CHUNK_OVERLAP)\n    summaries = []\n\n    for i, chunk in enumerate(chunks, 1):\n        if not chunk.strip():\n            print(f\"⚠️ Skipping empty chunk {i}\")\n            continue\n        try:\n            summary = groq_generate(\n                f\"Summarize the following paper content:\\n\\n{chunk}\",\n                max_tokens=MAX_SUMMARY_TOKENS,\n                temperature=TEMPERATURE,\n            )\n            if summary and summary.strip():\n                summaries.append(summary.strip())\n        except Exception as e:\n            print(f\"✗ Summarization failed on chunk {i}: {e}\")\n\n    return \"\\n\\n\".join(summaries) if summaries else None\n\ndef search_arxiv(query, max_results=10): \n    try: \n       search = arxiv.Search(\n         query=query,\n         max_results=max_results,\n         sort_by=arxiv.SortCriterion.Relevance \n       ) \n       return list(search.results()) \n    except Exception as e: \n       print(f\"✗ Arxiv search failed: {e}\") \n       return []\n\ndef groq_generate(prompt, max_tokens=200, temperature=0.7):\n    if not prompt or not prompt.strip():\n        print(\"⚠️ Empty prompt given to Groq, skipping.\")\n        return None\n    try:\n        client = Groq(api_key=groq_api_key)\n        resp = client.chat.completions.create(\n            model=\"llama-3.1-8b-instant\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=max_tokens,\n            temperature=temperature\n        ) \n        return resp.choices[0].message.content.strip()\n    except Exception as e: \n        print(f\"✗ Groq call failed: {e}\")\n        return None\n\ndef extract_paper_text(paper, folder=PAPERS_DIR):\n    try:\n        pdf_path = os.path.join(folder, f\"{paper.get_short_id()}.pdf\")\n        paper.download_pdf(filename=pdf_path)\n        return f\"Title: {paper.title.strip()}\\n\\nAbstract: {paper.summary.strip()}\"\n    except Exception as e:\n        print(f\"✗ Failed to extract text: {e}\")\n        return \"\"\n\ndef save_summary(paper, summary, folder=PAPERS_DIR):\n    try:\n        fname = os.path.join(folder, f\"{paper.get_short_id()}_summary.txt\")\n        os.makedirs(folder, exist_ok=True)\n        with open(fname, \"w\", encoding=\"utf-8\") as f:\n            f.write(summary)\n        print(f\"✓ Saved summary to {fname}\")\n    except Exception as e:\n        print(f\"✗ Failed to save summary: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T05:28:49.453834Z","iopub.execute_input":"2025-08-28T05:28:49.454170Z","iopub.status.idle":"2025-08-28T05:28:49.465862Z","shell.execute_reply.started":"2025-08-28T05:28:49.454145Z","shell.execute_reply":"2025-08-28T05:28:49.464905Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Iterative Paper Pipeline","metadata":{}},{"cell_type":"code","source":"def run_iteration(search_term, prev_paper_title=\"\"):\n    print(colored(f\"Searching arXiv for: {search_term}\", \"green\"))\n    papers = search_arxiv(search_term)\n\n    if not papers:\n        print(colored(\"⚠️ No papers found. Keeping same search term.\", \"yellow\"))\n        return search_term, None\n\n    chosen_paper = papers[0]  # take top result\n    print(colored(f\"Chosen paper: {chosen_paper.title}\", \"magenta\"))\n\n    text = extract_paper_text(chosen_paper)\n    if text:\n        final_summary = safe_summarize_text(text)\n        if final_summary:\n            save_summary(chosen_paper, final_summary)\n        \n# --- KEY CHANGE: force Groq to output only a topic ---\n    new_prompt = (\n        f\"Based on the paper '{chosen_paper.title}', suggest ONE concise related \"\n        f\"research topic (5-8 words max, no punctuation).\"\n    )\n    new_term = groq_generate(new_prompt, max_tokens=30)\n\n    if not new_term or len(new_term.split()) < 2:\n        print(colored(\"⚠️ Invalid search term generated, reusing old term.\", \"yellow\"))\n        new_term = search_term\n\n    return new_term, chosen_paper\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T05:28:55.040075Z","iopub.execute_input":"2025-08-28T05:28:55.040374Z","iopub.status.idle":"2025-08-28T05:28:55.046907Z","shell.execute_reply.started":"2025-08-28T05:28:55.040353Z","shell.execute_reply":"2025-08-28T05:28:55.046095Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Main Loop","metadata":{}},{"cell_type":"code","source":"print(colored(\"=== LLaMA Research Assistant (Groq) ===\", \"cyan\"))\nif not groq_api_key:\n    raise SystemExit(\"Please set GROQ_API_KEY and re-run.\")\n\nensure_dir(PAPERS_DIR)\n\nchosen_paper = None\nsearch_term = INITIAL_SEARCH_TERM or \"artificial intelligence research\"\n\nfor turn in range(1, NUMBER_OF_TURNS + 1):\n    print(colored(f\"\\n=== Research Turn {turn}/{NUMBER_OF_TURNS} ===\", \"cyan\"))\n\n    prev_title = chosen_paper.title if chosen_paper else \"No previous paper\"\n\n    search_term, chosen_paper = run_iteration(\n        search_term,\n        prev_paper_title=prev_title\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T05:29:00.221078Z","iopub.execute_input":"2025-08-28T05:29:00.221627Z","iopub.status.idle":"2025-08-28T05:30:49.525912Z","shell.execute_reply.started":"2025-08-28T05:29:00.221597Z","shell.execute_reply":"2025-08-28T05:30:49.525140Z"}},"outputs":[{"name":"stdout","text":"=== LLaMA Research Assistant (Groq) ===\n\n=== Research Turn 1/10 ===\nSearching arXiv for: coding ability of large language models\nChosen paper: Testing the Effect of Code Documentation on Large Language Model Code Understanding\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/2345965408.py:29: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n  return list(search.results())\n","output_type":"stream"},{"name":"stdout","text":"✓ Saved summary to research_papers/2404.03114v1_summary.txt\n\n=== Research Turn 2/10 ===\nSearching arXiv for: Assessing the Impact of Code Comments on Debugging.\nChosen paper: Out-Of-Place debugging: a debugging architecture to reduce debugging interference\n✓ Saved summary to research_papers/1811.02034v1_summary.txt\n\n=== Research Turn 3/10 ===\nSearching arXiv for: Reducing Debugging Interference in Cloud Computing Environments\nChosen paper: Out-Of-Place debugging: a debugging architecture to reduce debugging interference\n✓ Saved summary to research_papers/1811.02034v1_summary.txt\n\n=== Research Turn 4/10 ===\nSearching arXiv for: Investigating Real-Time Debugging Techniques for High-Performance Systems\nChosen paper: Out-Of-Place debugging: a debugging architecture to reduce debugging interference\n✓ Saved summary to research_papers/1811.02034v1_summary.txt\n\n=== Research Turn 5/10 ===\nSearching arXiv for: Improving debugging techniques for distributed and concurrent systems.\nChosen paper: Automated Dynamic Concurrency Analysis for Go\n✓ Saved summary to research_papers/2105.11064v1_summary.txt\n\n=== Research Turn 6/10 ===\nSearching arXiv for: Analyzing Concurrency Bugs in Parallel Functional Programming Languages\nChosen paper: Automated Dynamic Concurrency Analysis for Go\n✓ Saved summary to research_papers/2105.11064v1_summary.txt\n\n=== Research Turn 7/10 ===\nSearching arXiv for: Analyzing Concurrency Bugs in Complex Distributed Systems.\nChosen paper: Towards Extending the Range of Bugs That Automated Program Repair Can Handle\n✓ Saved summary to research_papers/2211.03911v1_summary.txt\n\n=== Research Turn 8/10 ===\nSearching arXiv for: Improving Automated Program Repair for Complex Defects\nChosen paper: Can defects be fixed with weak test suites? An analysis of 50 defects from Defects4J\n✓ Saved summary to research_papers/1705.04149v2_summary.txt\n\n=== Research Turn 9/10 ===\nSearching arXiv for: Evaluating the effectiveness of weak test suites fixes.\nChosen paper: Suggestions on Test Suite Improvements with Automatic Infection and Propagation Analysis\n✓ Saved summary to research_papers/1909.04770v1_summary.txt\n\n=== Research Turn 10/10 ===\nSearching arXiv for: Analyzing Propagation of Faults in Open Source Code\nChosen paper: ARMORY: Fully Automated and Exhaustive Fault Simulation on ARM-M Binaries\n✓ Saved summary to research_papers/2105.13769v1_summary.txt\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"os.listdir(\"research_papers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T09:44:34.352899Z","iopub.execute_input":"2025-08-25T09:44:34.353876Z","iopub.status.idle":"2025-08-25T09:44:34.361788Z","shell.execute_reply.started":"2025-08-25T09:44:34.353848Z","shell.execute_reply":"2025-08-25T09:44:34.360721Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"['coding_ability_of_large_language_models',\n '2411.10583v2.pdf',\n '2404.03114v1.pdf',\n '2408.16498v2.pdf',\n '2404.03114v1_summary.txt',\n '2408.16498v2_summary.txt',\n '2411.10583v2_summary.txt']"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"with open(\"research_papers/2404.03114v1_summary.txt\", \"r\") as f:\n    print(f.read())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T09:48:33.525724Z","iopub.execute_input":"2025-08-25T09:48:33.526065Z","iopub.status.idle":"2025-08-25T09:48:33.531946Z","shell.execute_reply.started":"2025-08-25T09:48:33.526025Z","shell.execute_reply":"2025-08-25T09:48:33.530762Z"}},"outputs":[{"name":"stdout","text":"Researchers conducted an empirical analysis to investigate how code documentation affects the understanding of Large Language Models (LLMs) in code. They found that:\n\n* Providing LLMs with \"incorrect\" documentation significantly hinders their ability to understand code.\n* Incomplete or missing documentation does not seem to have a significant impact on LLMs' ability to understand code.\n\nThis suggests that the accuracy and quality of code documentation play a crucial role in LLMs' code understanding capabilities.\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"import shutil\n\n# Zip the research_papers folder\nshutil.make_archive(\"research_papers\", \"zip\", \"research_papers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T09:51:14.690798Z","iopub.execute_input":"2025-08-25T09:51:14.691226Z","iopub.status.idle":"2025-08-25T09:51:14.753239Z","shell.execute_reply.started":"2025-08-25T09:51:14.691201Z","shell.execute_reply":"2025-08-25T09:51:14.752282Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/research_papers.zip'"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Create a clickable download link\nFileLink(\"research_papers.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T09:56:47.150169Z","iopub.execute_input":"2025-08-25T09:56:47.150511Z","iopub.status.idle":"2025-08-25T09:56:47.156941Z","shell.execute_reply.started":"2025-08-25T09:56:47.150489Z","shell.execute_reply":"2025-08-25T09:56:47.155921Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/research_papers.zip","text/html":"<a href='research_papers.zip' target='_blank'>research_papers.zip</a><br>"},"metadata":{}}],"execution_count":61}]}